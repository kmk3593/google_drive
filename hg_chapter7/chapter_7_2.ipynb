{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_7_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk3593/google_drive/blob/main/hg_chapter7/chapter_7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 심층 신경망\n",
        "- 인공신경망에 층을 여러 개 추가하여 패션 MNIST 데이터셋을 분류한다.\n",
        "- 동시에 케라스로 심층 신경망을 만들어본다."
      ],
      "metadata": {
        "id": "YUD4nGwiZPSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 368p 그림 참고\n",
        "- 케라스로 API를 사용해 패션 MNIST 데이터셋을 불러온다."
      ],
      "metadata": {
        "id": "_tfHsFELZe1Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5jYVlFuZIZu",
        "outputId": "1b2ce512-c039-4883-c654-aaea54cd49f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지의 픽셀값을 0~255 범위에서 0~1로 변환\n",
        "- 28x28 크기의 2차원 배열을 784 크기인 1차원 배열로 펼친다.\n",
        "- train_test_split() 함수로 훈련 세트와 검증 세트로 나눈다."
      ],
      "metadata": {
        "id": "NWWTn8WBzwPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qxLz8S3Xb9Fu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력층과 출력층 사이에 밀집층을 만들 예정이다.\n",
        "- 은닉층 : 입력층과 출력층 사이에 있는 모든 층 \n",
        "- 케라스의 Dense 클래스로 다음 내용을 만든다.\n",
        "  - sigmoid 활성화 함수를 사용한 은닉층\n",
        "  - softmax 함수를 사용한 출력층"
      ],
      "metadata": {
        "id": "rgw5rXMRcQSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 층을 추가하는 방법\n",
        "  - Dense 클래스의 객체 dense1, 2를 만들어 Sequential 클래스에 전달한다."
      ],
      "metadata": {
        "id": "nCM5pXTkLsi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "4LrKoLZXb_Y2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- dense1이 은닉층이고 100개의 뉴런을 가진 밀집층이다.\n",
        "  - 활성화 함수를 'sigmoid'로 지정했고 매개변수로 입력의 크기를 (784,)로 지정했다.\n",
        "- dense2는 출력층이다.\n",
        "  - 10개의 클래스를 분류하므로 10개의 뉴런을 두었고 활성화 함수는 softmax로 지정했다."
      ],
      "metadata": {
        "id": "nOUJ7jcj03su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 심층 신경망\n",
        "  - 컨셉만 이해하라!\n",
        "  - 직접 신경망 만들 일은 없고 가져다 쓰기만 하면 된다."
      ],
      "metadata": {
        "id": "ir9Rozk0cch1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 앞의 dense1과 dense2 객체를 Sequential 클래스에 추가하여 심층 신경망을 만들 예정이다."
      ],
      "metadata": {
        "id": "YdBipdKc1Tho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0czPrdyfcbZ9",
        "outputId": "ecf12b59-7282-49e5-ced2-e231811bf75b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위와 같이 Sequential 클래스의 객체를 만들 때 여러 개의 층을 추가하려면 층을 리스트로 만들어 전달해야 한다.\n",
        "- model.summary()로 층에 대한 정보를 얻을 수 있다.\n",
        "  - 첫 줄에 모델의 이름이 나온다.\n",
        "  - 이 모델에 들어 있는 층이 순서대로 나열된다.\n",
        "    - 이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서로 나열된다.\n",
        "  - 층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 출력된다.\n",
        "  - name 매개변수로 이름을 지정하지 않으면 디폴트인 'dense'로 네이밍된다.\n",
        "  - 출력 크기는 (None,100)인데, 첫 번째 차원은 샘플 개수를 나타낸다.\n",
        "    - None인 이유는 어떤 배치 크기에도 잘 대응하기 위함이다.\n",
        "    - 두 번째 차원인 100은 뉴런 개수가 100이며, 따라서 100개의 출력이 나옴을 나타낸다."
      ],
      "metadata": {
        "id": "LrBINtu41eo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 층을 추가하는 다른 방법\n",
        "- Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만든다."
      ],
      "metadata": {
        "id": "0fSCkHnDdIYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),   # 층을 쌓아간다\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')                         # 층을 쌓아간다\n",
        "], name='패션 MNIST 모델')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgREMelXdL_0",
        "outputId": "7dc9c3fe-c194-4abb-ecc4-b56d2a9a7afc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 층을 추가하는 다른 방법 2\n",
        "- Sequential 클래스의 객체를 만들고 이 객체의 add() 메서드를 호출하여 층을 추가한다."
      ],
      "metadata": {
        "id": "tfstgWEYd_Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))    # 층을 쌓아간다\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))                         # 층을 쌓아간다\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfPoO1YFd43U",
        "outputId": "4a1a40d0-4216-4ce0-cb3e-8dea35058c9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 모델을 훈련한다.\n",
        "  - 반복할 에포크 횟수를 epochs 매개변수로 지정"
      ],
      "metadata": {
        "id": "b3H8yn2D7XtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzd9nWR-eKh7",
        "outputId": "cf415632-127d-4a2d-ce2d-6052f1b82f30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 3ms/step - loss: 0.5628 - accuracy: 0.8069\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4087 - accuracy: 0.8522\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3747 - accuracy: 0.8645\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3506 - accuracy: 0.8737\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3344 - accuracy: 0.8784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bcb861b50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 렐루 함수\n",
        "  - 층이 많은 신경망일수록 그 효과가 누적되어 학습이 어려워진다.\n",
        "  - 이를 개선하기 위한 활성화 함수이다. \n",
        "  - relu() 함수는 입력이 양수일 그냥 통과시키고, 입력이 음수라면 0으로 만든다. "
      ],
      "metadata": {
        "id": "Gg7Tu1dRMoxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Flatten 클래스\n",
        "  - 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼친다.\n",
        "  - Flatten 클래스를 층처럼 입렬층과 은닉층 사잉에 추가하기 때문에 이를 층이라 부른다. \n",
        "  - 다음 코드처럼 입력층 바로 뒤에 추가한다."
      ],
      "metadata": {
        "id": "okVAfzQmNGBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))  # 기존 코드 비교\n",
        "model.add(keras.layers.Dense(100, activation='relu')) # relu 로 변경\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyGE0T6Helc7",
        "outputId": "24160a2e-938e-4195-e36e-48ffe28186bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련 데이터를 다시 준비해서 모델을 훈련한다."
      ],
      "metadata": {
        "id": "nflqd7HtN4hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "JmcKyO34I9AH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 컴파일하고 훈련한다."
      ],
      "metadata": {
        "id": "o6idOAVhN9i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3awGy4_JYW3",
        "outputId": "26f385b8-29cd-4830-b93f-390a7cd50bcb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5283 - accuracy: 0.8151\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3926 - accuracy: 0.8602\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3562 - accuracy: 0.8713\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3336 - accuracy: 0.8809\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3203 - accuracy: 0.8853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bcb762a10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시그모이드 함수를 사용했을 때와 비교하면 성능이 조금 향상되었다.\n",
        "- 검증 세트에서의 성능도 확인하자."
      ],
      "metadata": {
        "id": "tn9HX-fIOC3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-CAEsmFIx93",
        "outputId": "f636b55e-7399-4fbf-ea31-95793a88a19d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3713 - accuracy: 0.8717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3712655007839203, 0.871749997138977]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검증 성능도 향상되었다."
      ],
      "metadata": {
        "id": "u57gj48jOOeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(\n",
        "    train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "D3xGjOUaL8Q0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMEGTa9ZL96E",
        "outputId": "03c15219-7f49-462e-86f3-677640caf2a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3094 - accuracy: 0.8890\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2989 - accuracy: 0.8951\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2902 - accuracy: 0.8974\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2825 - accuracy: 0.9018\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.9024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5bcb835d10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30oUmCCeMA0_",
        "outputId": "1ae9ba3a-17b1-4685-b970-009eaa7f4faa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 1ms/step - loss: 0.4110 - accuracy: 0.8792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41104814410209656, 0.8791666626930237]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 옵티마이저의 개념\n",
        "--> Adam 사용하라\n",
        "--> why Adam? 최고점을 찾기 위해서\n",
        "  + 스텝방향 & 스템사이즈를 모두 고려한 옵티마이저\n",
        "  + 스텝방향 : GD, SGD, Momentum, NAG\n",
        "  + 스텝사이즈 : GD, SGD, Adagrad, RMSProp"
      ],
      "metadata": {
        "id": "vv8TmVi0JeiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 하이퍼 파라미터는 사람이 지정해야 하는 파라미터\n",
        "- 신경망에는 특히 하이퍼 파라미터가 많다.\n",
        "- 은닉층의 뉴런 개수도 하이퍼 파라미터이다.\n",
        "- compile() 에서는 케라스의 기본 하강법 알고리즘인 RMSprop을 사용했다.\n",
        "  - 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공한다.\n",
        "  - 이들을 '옵티마이저'라고 부른다."
      ],
      "metadata": {
        "id": "-n2PLsTmOcgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 옵티마이저 \n",
        "- 381p\n",
        "- SGD 옵티마이저를 사용하려면 compile() 메서드의 optimizer 매개변수를 'sgd'로 지정"
      ],
      "metadata": {
        "id": "GSOz5rbrMDmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "wovulboVMH5x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 'sgd' 문자열은 이 클래스의 기본 설정 매개변수로 생성한 객체와 동일하다.\n",
        "- 다음 코드는 위의 코드와 정확히 동일하다."
      ],
      "metadata": {
        "id": "FnFX1YYyMoTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD()\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "jazBLXESMa2L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 382p\n",
        "- learning_rate = 0.1\n",
        "  - 만약 SGD 클래스의 학습률 기본값이 0.01일 때 이를 바꾸고 싶다면 다음와 같이 지정한다.\n",
        "- 랜덤서치, 그리드서치\n",
        "- 딥러닝에서도 하이퍼파라미터 튜닝"
      ],
      "metadata": {
        "id": "AhS9WQ6mMyVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate = 0.1)"
      ],
      "metadata": {
        "id": "sqrS09xVUwi2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공한다.\n",
        "- SGD 클래서의 momentum 매개변수의 기본값은 0이다. 보통 0.9이상을 지정한다.\n",
        "- 다음처럼 SGD 클래스의 nesterov 매개변수를 기본값 False 에서 True로 바꾸면 네스테로프 모멘텀 최적화를 사용한다.\n",
        "  - 테스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현한다.\n",
        "  - 대부분의 경우 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공한다."
      ],
      "metadata": {
        "id": "_yl8lVqsUzqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(momentum = 0.9, nesterov = True)"
      ],
      "metadata": {
        "id": "KUSM9i2dM7Qd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 적응적 학습률\n",
        "  - 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있다.\n",
        "  - 이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높다.\n",
        "  - 이런 학습률을 적응적 학습률이라고 한다."
      ],
      "metadata": {
        "id": "T95ySiTUWdhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Adagrad() 클래스\n",
        "  - 적응적 학습률을 사용하는 대표적인 옵티마이저이다.\n",
        "  - optimizer 매개변수에서 지정할 수 있다.\n",
        "  - optimizer 매개변수의 기본값이 바로 rmsprop이다."
      ],
      "metadata": {
        "id": "2Wht83RuQ1c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "tJOWMA7hQ8Mq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- RMSprop() 클래스\n",
        "  - 적응적 학습률을 사용하는 대표적인 옵티마이저이다.\n",
        "  - optimizer 매개변수에서 지정할 수 있다.\n",
        "  - optimizer 매개변수의 기본값이 바로 rmsprop이다."
      ],
      "metadata": {
        "id": "z3N3pGA6RptM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "V2M8MokeROkZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다만, Adam을 사용하는 것이 더 좋다.\n",
        "- Adam\n",
        "  - 모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다.\n",
        "  - 적응적 학습률을 사용하는 이 3개의 클래스는 learning_rate 매개변수의 기본값을 0.001로 두고 사용한다."
      ],
      "metadata": {
        "id": "vFnne253SIXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Adam 클래스의 매개변수 기본값을 사용해 패션 MNIST 모델을 훈련해본다.\n",
        "- 일단 모델을 다시 생성한다."
      ],
      "metadata": {
        "id": "RkrZORJDXz0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))  # 기존 코드 비교\n",
        "model.add(keras.layers.Dense(100, activation='relu')) # relu 로 변경\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "ZtlRP4FgX8YP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- compile() 메서드의 optimizer를 'adam'으로 설정하고 5번의 에포크 동안 훈련한다."
      ],
      "metadata": {
        "id": "FfrCQJtTX_-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQK5qVlVR3Tg",
        "outputId": "11c67fab-eab3-440f-d286-a9737c45df68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5293 - accuracy: 0.8155\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3980 - accuracy: 0.8571\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3542 - accuracy: 0.8713\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3287 - accuracy: 0.8798\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.8867\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32961416244506836, 0.8805833458900452]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결과를 보면 기본 RMSprop을 사용했을 때와 거의 같은 성능을 보인다.\n",
        "- 검증 세트에서의  성능도 확인한다."
      ],
      "metadata": {
        "id": "mwi5DqtAYU3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu2jLKs5Yc7h",
        "outputId": "792c1503-ea80-4797-a7cb-9f10627f4e3a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32961416244506836, 0.8805833458900452]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 환경마다 차이가 있을 수 있지만 여기서는 기본 RMSprop보다 조금 더 나은 성능을 보인다."
      ],
      "metadata": {
        "id": "ZSDvjnWVYiDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Reference : 혼자 공부하는 머신러닝 + 딥러닝 "
      ],
      "metadata": {
        "id": "-76g53YKSNty"
      }
    }
  ]
}